{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13541a18",
   "metadata": {},
   "source": [
    "# Scan output_files/output_sheets for CSV Files\n",
    "\n",
    "This notebook scans the `output_files/output_sheets` directory and lists all `.csv` files it finds.\n",
    "\n",
    "Future steps: You can expand this notebook to read, process, or plot the data from these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory to scan (relative path)\n",
    "output_sheets_dir = Path('../output_files/output_sheets')\n",
    "\n",
    "# List to store found CSV filenames\n",
    "csv_files = []\n",
    "\n",
    "# Scan the directory for .csv files\n",
    "if output_sheets_dir.exists() and output_sheets_dir.is_dir():\n",
    "    for filename in os.listdir(output_sheets_dir):\n",
    "        if filename.lower().endswith('.csv'):\n",
    "            csv_files.append(filename)\n",
    "else:\n",
    "    print(f'Directory not found: {output_sheets_dir}')\n",
    "\n",
    "# Print the found CSV files\n",
    "print('Found CSV files:')\n",
    "for fname in csv_files:\n",
    "    print(f'- {fname}')\n",
    "\n",
    "# ---\n",
    "# Future expansion:\n",
    "# - Read CSV files\n",
    "# - Process data\n",
    "# - Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e49895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pastas Model Analysis for Each CSV File ---\n",
    "import pandas as pd\n",
    "import pastas as ps\n",
    "import numpy as np\n",
    "\n",
    "# Example: set the relative paths to precipitation and evaporation input files\n",
    "input_prec_path = '../input_files/input_prec/prec_station_249.csv'  # Update filename as needed\n",
    "input_evap_path = '../input_files/input_evap/evap_station_249.csv'   # Update filename as needed\n",
    "\n",
    "# Read precipitation and evaporation CSVs as pandas Series, always using first column as date and second as value\n",
    "def read_timeseries_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    date_col = df.columns[0]\n",
    "    value_col = df.columns[1]\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.set_index(date_col)\n",
    "    series = df[value_col].dropna()\n",
    "    return series\n",
    "\n",
    "# Try reading the files and check if they are pandas Series with DateTimeIndex\n",
    "try:\n",
    "    input_prec = read_timeseries_csv(input_prec_path)\n",
    "    assert isinstance(input_prec, pd.Series) and isinstance(input_prec.index, pd.DatetimeIndex)\n",
    "    print(f\"input_prec loaded: {input_prec.shape}, index type: {type(input_prec.index)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load input_prec: {e}\")\n",
    "\n",
    "try:\n",
    "    input_evap = read_timeseries_csv(input_evap_path)\n",
    "    assert isinstance(input_evap, pd.Series) and isinstance(input_evap.index, pd.DatetimeIndex)\n",
    "    print(f\"input_evap loaded: {input_evap.shape}, index type: {type(input_evap.index)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load input_evap: {e}\")\n",
    "# waterhoogte_daily_mean = ...  # pd.Series with datetime index (optional extra stressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b91c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_evap.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f88aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure csv_files is defined and populated in this cell, in case previous cells were not run\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "output_sheets_dir = Path('../output_files/output_sheets')\n",
    "csv_files = []\n",
    "if output_sheets_dir.exists() and output_sheets_dir.is_dir():\n",
    "    for filename in os.listdir(output_sheets_dir):\n",
    "        if filename.lower().endswith('.csv'):\n",
    "            csv_files.append(filename)\n",
    "else:\n",
    "    print(f'Directory not found: {output_sheets_dir}')\n",
    "\n",
    "# Define model components\n",
    "recharge_models = {\n",
    "    \"Linear\": ps.rch.Linear(),\n",
    "    \"FlexModel\": ps.rch.FlexModel(),\n",
    "    \"Berendrecht\": ps.rch.Berendrecht()\n",
    "}\n",
    "response_functions = {\n",
    "    \"Exponential\": ps.Exponential(),\n",
    "    \"Gamma\": ps.Gamma(),\n",
    "    \"DoubleExponential\": ps.DoubleExponential(),\n",
    "    \"Hantush\": ps.Hantush(),\n",
    "    \"FourParam\": ps.FourParam(),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Cap the number of files to process\n",
    "max_files = 3\n",
    "csv_files_to_process = csv_files[:max_files]\n",
    "print(f\"Processing up to {max_files} CSV files (found {len(csv_files)})\")\n",
    "\n",
    "# --- Loop over each observation file ---\n",
    "for csv_file in csv_files_to_process:\n",
    "    print(f\"\\n=== Processing file: {csv_file} ===\")\n",
    "    try:\n",
    "        df = pd.read_csv(output_sheets_dir / csv_file, parse_dates=[\"Timestamp\"])\n",
    "        df = df.rename(columns={\"head\": \"head_raw\"})\n",
    "        df = df.set_index(\"Timestamp\")\n",
    "        head_daily_median = df[\"head_raw\"].resample('D').median().dropna()\n",
    "\n",
    "        # Determine time window for slicing input data\n",
    "        start_date = head_daily_median.index.min()\n",
    "        end_date = head_daily_median.index.max()\n",
    "\n",
    "        # Slice preloaded input data to match this file's time range\n",
    "        input_prec_slice = input_prec.loc[start_date:end_date].copy()\n",
    "        input_evap_slice = input_evap.loc[start_date:end_date].copy()\n",
    "        print(input_prec_slice[0:10])\n",
    "        print(input_evap_slice[0:10])\n",
    "\n",
    "        # Optional safety check to ensure alignment\n",
    "        if not input_prec_slice.index.equals(head_daily_median.index):\n",
    "            input_prec_slice = input_prec_slice.reindex(head_daily_median.index)\n",
    "        if not input_evap_slice.index.equals(head_daily_median.index):\n",
    "            input_evap_slice = input_evap_slice.reindex(head_daily_median.index)\n",
    "\n",
    "        # Loop over recharge models and response functions\n",
    "        # 1) Fit all recharge Ã— response variants\n",
    "        for rch_name, rch_model in recharge_models.items():\n",
    "            for rfunc_name, rfunc in response_functions.items():\n",
    "                model_name = f\"{rch_name}_{rfunc_name}\"\n",
    "                print(f\"  Running model: {model_name}\")\n",
    "                try:\n",
    "                    ml = ps.Model(head_daily_median, name=model_name)\n",
    "                    rm = ps.RechargeModel(\n",
    "                        prec=input_prec_slice,\n",
    "                        evap=input_evap_slice,\n",
    "                        recharge=rch_model,\n",
    "                        rfunc=rfunc,\n",
    "                        name=\"rch\"\n",
    "                    )\n",
    "                    ml.add_stressmodel(rm)\n",
    "                    ml.add_noisemodel(ps.ArNoiseModel())\n",
    "                    ml.solve(report=True)\n",
    "                    stats = ml.stats\n",
    "                    results.append({\n",
    "                        \"file\": csv_file,\n",
    "                        \"model\": model_name,\n",
    "                        \"RechargeModel\": rch_name,\n",
    "                        \"RechargeRfunc\": rfunc_name,\n",
    "                        \"EVP\": stats.evp(),\n",
    "                        \"R2\": stats.rsq(),\n",
    "                        \"RMSE\": stats.rmse(),\n",
    "                        \"AIC\": stats.aic(),\n",
    "                        \"BIC\": stats.bic()\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"    Model {model_name} failed: {e}\")\n",
    "                    results.append({\n",
    "                        \"file\": csv_file,\n",
    "                        \"model\": model_name,\n",
    "                        \"RechargeModel\": rch_name,\n",
    "                        \"RechargeRfunc\": rfunc_name,\n",
    "                        \"EVP\": None,\n",
    "                        \"R2\": None,\n",
    "                        \"RMSE\": None,\n",
    "                        \"AIC\": None,\n",
    "                        \"BIC\": None,\n",
    "                        \"error\": str(e)\n",
    "                    })\n",
    "\n",
    "        # 2) Now fit the TarsoModel once, using Exponential (the only supported rfunc)\n",
    "        tarso_name = \"Tarso_Exp\"\n",
    "        print(f\"\\n  Running Tarso model: {tarso_name}\")\n",
    "        try:\n",
    "            ml2 = ps.Model(head_daily_median, name=tarso_name)\n",
    "            tm = ps.TarsoModel(\n",
    "                prec=input_prec_slice,\n",
    "                evap=input_evap_slice,\n",
    "                oseries=head_daily_median,  # lets Tarso auto-set dmin/dmax\n",
    "                rfunc=ps.Exponential(),     # must be Exponential()\n",
    "                name=\"tarso\"\n",
    "            )\n",
    "            ml2.add_stressmodel(tm)\n",
    "            ml2.add_noisemodel(ps.ArNoiseModel())\n",
    "            ml2.solve(report=True)\n",
    "            stats2 = ml2.stats\n",
    "            results.append({\n",
    "                \"file\": csv_file,\n",
    "                \"model\": tarso_name,\n",
    "                \"RechargeModel\": \"Tarso\",\n",
    "                \"RechargeRfunc\": \"Exponential\",\n",
    "                \"EVP\": stats2.evp(),\n",
    "                \"R2\": stats2.rsq(),\n",
    "                \"RMSE\": stats2.rmse(),\n",
    "                \"AIC\": stats2.aic(),\n",
    "                \"BIC\": stats2.bic()\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"    Model {tarso_name} failed: {e}\")\n",
    "            results.append({\n",
    "                \"file\": csv_file,\n",
    "                \"model\": tarso_name,\n",
    "                \"RechargeModel\": \"Tarso\",\n",
    "                \"RechargeRfunc\": \"Exponential\",\n",
    "                \"EVP\": None,\n",
    "                \"R2\": None,\n",
    "                \"RMSE\": None,\n",
    "                \"AIC\": None,\n",
    "                \"BIC\": None,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to process file {csv_file}: {e}\")\n",
    "\n",
    "# Combine results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nCombined results (first 10 rows):\")\n",
    "print(results_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d571762",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8024e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ../output_files/model_results_monte_carlo.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define output path\n",
    "output_path = \"../output_files/model_results_monte_carlo.xlsx\"\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Results saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pastas-wv2030-gYPXqKkJ-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
